lmin <- opt_result$minimum
# Actualizar X
X =  rbind(X,X[k, ] - lmin * gradiente)
k <- k + 1
# Calcular las normas de X y el uevo X
normaX = norma(X[k,]-X[k-1,])/norma(X[k-1,])
tc = c(tc,normaX)
}
# Añadir al final la columna de resultados
X = cbind.data.frame(1:k,X,apply(X, 1, fx),tc)
X
# Ponerlo bonito para los resultados:
resu = as.data.frame(X)
names(resu) = c("Iter","X1","X2","Y","Tol")
resu |> round(digits = 4)
resu = resu |> round(digits = 4)
# Devolver los resultados bonitos
return(resu)
resu
rm(list=ls())
#### Paso 1 Definir los parametros iniciales ####
fx = function(X){((X[1]^2+X[2]-11)^2 + (X[1] + X[2]^2-7)^2) |> as.numeric()}
x = c(0,0) # Punto inicial
tol1 = 0.001
tol2 = 0.001
# Paramertros para la derivada y el método de busqueda
a = 0
b = 1
cauchy = function(fx,x,tol1,a,b){
# Parametros de inicio
tol2 = tol1
h = 0.0001
k = 1 # Punto de inicio par K
D = length(x) # Dimensiones de entrada
# Crear el objeto que guarda los valores de X
M = 100
X <- matrix(0, nrow = 1, ncol = D)
### Funciones necesarias ###
#Función para calcular el gradiente
gradienten <- function(fx, X, h) {
D <- length(X)  # Dimensiones de la entrada
resu <- numeric(D)
f0 <- fx(X)     # Valor de la función en X actual
for (i in 1:D) {
perturbado <- X
perturbado[i] <- perturbado[i] + h
resu[i] <- (fx(perturbado) - f0) / h
}
return(resu)
}
# Función en terminos de lambda que minimiza el valor de fx(x-lambda*grad)
fa <- function(lambda) { fx(X[k,] - lambda * gradiente) }
# Función par extraer la norma
norma <- function(VEC){sqrt(sum(VEC^2))}
#### Paso 3 implicito como criterio de parada
# Norma auxiliar
normaG = 5
normaX = 5
tc = c(normaX)
# Paso 3 que implica el bucle hasta la convergencia
while(normaG >= tol1 & normaX >= tol1  & k < M){
# PASO 2: Calcular gradiente numérico
gradiente <- gradienten(fx, X[k, ], h)
# PASO 3: Calcula la norma del gradiente
normaG <- norma(gradiente)
# Paso 4: Efectuar la busqueda unidireccional par encontrar lambda
opt_result <- optimize(fa, interval = c(a, b), tol = 1e-5)
lmin <- opt_result$minimum
# Actualizar X
X =  rbind(X,X[k, ] - lmin * gradiente)
k <- k + 1
# Calcular las normas de X y el uevo X
normaX = norma(X[k,]-X[k-1,])/norma(X[k-1,])
tc = c(tc,normaX)
}
# Añadir al final la columna de resultados
X = cbind.data.frame(1:k,X,apply(X, 1, fx),tc)
# Ponerlo bonito para los resultados:
resu = as.data.frame(X)
names(resu) = c("Iter","X1","X2","Y","Tol")
resu = resu |> round(digits = 4)
# Devolver los resultados bonitos
return(resu)
}
x
tol1
a
b
cauchy = function(fx,x,tol1,a,b)
)
rm(list=ls())
#### Paso 1 Definir los parametros iniciales ####
fx = function(X){((X[1]^2+X[2]-11)^2 + (X[1] + X[2]^2-7)^2) |> as.numeric()}
x = c(0,0) # Punto inicial
tol1 = 0.001
tol2 = 0.001
# Paramertros para la derivada y el método de busqueda
a = 0
b = 1
cauchy = function(fx,x,tol1,a,b){
# Parametros de inicio
tol2 = tol1
h = 0.0001
k = 1 # Punto de inicio par K
D = length(x) # Dimensiones de entrada
# Crear el objeto que guarda los valores de X
M = 100
X <- matrix(0, nrow = 1, ncol = D)
### Funciones necesarias ###
#Función para calcular el gradiente
gradienten <- function(fx, X, h) {
D <- length(X)  # Dimensiones de la entrada
resu <- numeric(D)
f0 <- fx(X)     # Valor de la función en X actual
for (i in 1:D) {
perturbado <- X
perturbado[i] <- perturbado[i] + h
resu[i] <- (fx(perturbado) - f0) / h
}
return(resu)
}
# Función en terminos de lambda que minimiza el valor de fx(x-lambda*grad)
fa <- function(lambda) { fx(X[k,] - lambda * gradiente) }
# Función par extraer la norma
norma <- function(VEC){sqrt(sum(VEC^2))}
#### Paso 3 implicito como criterio de parada
# Norma auxiliar
normaG = 5
normaX = 5
tc = c(normaX)
# Paso 3 que implica el bucle hasta la convergencia
while(normaG >= tol1 & normaX >= tol1  & k < M){
# PASO 2: Calcular gradiente numérico
gradiente <- gradienten(fx, X[k, ], h)
# PASO 3: Calcula la norma del gradiente
normaG <- norma(gradiente)
# Paso 4: Efectuar la busqueda unidireccional par encontrar lambda
opt_result <- optimize(fa, interval = c(a, b), tol = 1e-5)
lmin <- opt_result$minimum
# Actualizar X
X =  rbind(X,X[k, ] - lmin * gradiente)
k <- k + 1
# Calcular las normas de X y el uevo X
normaX = norma(X[k,]-X[k-1,])/norma(X[k-1,])
tc = c(tc,normaX)
}
# Añadir al final la columna de resultados
X = cbind.data.frame(1:k,X,apply(X, 1, fx),tc)
# Ponerlo bonito para los resultados:
resu = as.data.frame(X)
names(resu) = c("Iter","X1","X2","Y","Tol")
resu = resu |> round(digits = 4)
# Devolver los resultados bonitos
return(resu)
}
cauchy(fx,x,tol1,a,b)
cauchy(fx,x,tol1,-10,2)
cauchy(fx,x,tol1,-10,0)
cauchy(fx,c(-10,-10),tol1,-10,0)
cauchy(fx,c(-10,-10),tol1,-50,50)
cauchy(fx,c(-10,-10),tol1,-10,10)
cauchy(fx,x,tol1,0,1)
#### Función de Cauchy ####
cauchy = function(fx,x,tol1,a,b){
# Parametros de inicio
tol2 = tol1
h = 0.0001
k = 1 # Punto de inicio par K
D = length(x) # Dimensiones de entrada
# Crear el objeto que guarda los valores de X
M = 100
X <- matrix(0, nrow = 1, ncol = D)
### Funciones necesarias ###
#Función para calcular el gradiente
gradienten <- function(fx, X, h) {
D <- length(X)  # Dimensiones de la entrada
resu <- numeric(D)
f0 <- fx(X)     # Valor de la función en X actual
for (i in 1:D) {
perturbado <- X
perturbado[i] <- perturbado[i] + h
resu[i] <- (fx(perturbado) - f0) / h
}
return(resu)
}
# Función en terminos de lambda que minimiza el valor de fx(x-lambda*grad)
fa <- function(lambda) { fx(X[k,] - lambda * gradiente) }
# Función par extraer la norma
norma <- function(VEC){sqrt(sum(VEC^2))}
#### Paso 3 implicito como criterio de parada
# Norma auxiliar
normaG = 5
normaX = 5
tc = c(normaX)
# Paso 3 que implica el bucle hasta la convergencia
while(normaG >= tol1 & normaX >= tol1  & k < M){
# PASO 2: Calcular gradiente numérico
gradiente <- gradienten(fx, X[k, ], h)
# PASO 3: Calcula la norma del gradiente
normaG <- norma(gradiente)
# Paso 4: Efectuar la busqueda unidireccional par encontrar lambda
opt_result <- optimize(fa, interval = c(a, b), tol = 1e-5)
lmin <- opt_result$minimum
# Actualizar X
X =  rbind(X,X[k, ] - lmin * gradiente)
k <- k + 1
# Calcular las normas de X y el uevo X
normaX = norma(X[k,]-X[k-1,])/norma(X[k-1,])
tc = c(tc,normaX)
}
# Añadir al final la columna de resultados
X = cbind.data.frame(1:k,X,apply(X, 1, fx),tc)
# Ponerlo bonito para los resultados:
resu = as.data.frame(X)
names(resu) = c("Iter","X1","X2","Y","Tol")
resu = resu |> round(digits = 4)
# Devolver los resultados bonitos
return(resu)
}
rm(list=ls())
cauchy = function(fx,x,tol1,a,b){
# Parametros de inicio
tol2 = tol1
h = 0.0001
k = 1 # Punto de inicio par K
D = length(x) # Dimensiones de entrada
# Crear el objeto que guarda los valores de X
M = 100
X <- matrix(0, nrow = 1, ncol = D)
### Funciones necesarias ###
#Función para calcular el gradiente
gradienten <- function(fx, X, h) {
D <- length(X)  # Dimensiones de la entrada
resu <- numeric(D)
f0 <- fx(X)     # Valor de la función en X actual
for (i in 1:D) {
perturbado <- X
perturbado[i] <- perturbado[i] + h
resu[i] <- (fx(perturbado) - f0) / h
}
return(resu)
}
# Función en terminos de lambda que minimiza el valor de fx(x-lambda*grad)
fa <- function(lambda) { fx(X[k,] - lambda * gradiente) }
# Función par extraer la norma
norma <- function(VEC){sqrt(sum(VEC^2))}
#### Paso 3 implicito como criterio de parada
# Norma auxiliar
normaG = 5
normaX = 5
tc = c(normaX)
# Paso 3 que implica el bucle hasta la convergencia
while(normaG >= tol1 & normaX >= tol1  & k < M){
# PASO 2: Calcular gradiente numérico
gradiente <- gradienten(fx, X[k, ], h)
# PASO 3: Calcula la norma del gradiente
normaG <- norma(gradiente)
# Paso 4: Efectuar la busqueda unidireccional par encontrar lambda
opt_result <- optimize(fa, interval = c(a, b), tol = 1e-5)
lmin <- opt_result$minimum
# Actualizar X
X =  rbind(X,X[k, ] - lmin * gradiente)
k <- k + 1
# Calcular las normas de X y el uevo X
normaX = norma(X[k,]-X[k-1,])/norma(X[k-1,])
tc = c(tc,normaX)
}
# Añadir al final la columna de resultados
X = cbind.data.frame(1:k,X,apply(X, 1, fx),tc)
# Ponerlo bonito para los resultados:
resu = as.data.frame(X)
names(resu) = c("Iter","X1","X2","Y","Tol")
resu = resu |> round(digits = 4)
# Devolver los resultados bonitos
return(resu)
}
cauchy = function(fx,x,tol1,a,b){
# Parametros de inicio
tol2 = tol1
h = 0.0001
k = 1 # Punto de inicio par K
D = length(x) # Dimensiones de entrada
# Crear el objeto que guarda los valores de X
M = 100
X <- matrix(0, nrow = 1, ncol = D)
### Funciones necesarias ###
#Función para calcular el gradiente
gradienten <- function(fx, X, h) {
D <- length(X)  # Dimensiones de la entrada
resu <- numeric(D)
f0 <- fx(X)     # Valor de la función en X actual
for (i in 1:D) {
perturbado <- X
perturbado[i] <- perturbado[i] + h
resu[i] <- (fx(perturbado) - f0) / h
}
return(resu)
}
# Función en terminos de lambda que minimiza el valor de fx(x-lambda*grad)
fa <- function(lambda) { fx(X[k,] - lambda * gradiente) }
# Función par extraer la norma
norma <- function(VEC){sqrt(sum(VEC^2))}
#### Paso 3 implicito como criterio de parada
# Norma auxiliar
normaG = 5
normaX = 5
tc = c(normaX)
# Paso 3 que implica el bucle hasta la convergencia
while(normaG >= tol1 & normaX >= tol1  & k < M){
# PASO 2: Calcular gradiente numérico
gradiente <- gradienten(fx, X[k, ], h)
# PASO 3: Calcula la norma del gradiente
normaG <- norma(gradiente)
# Paso 4: Efectuar la busqueda unidireccional par encontrar lambda
opt_result <- optimize(fa, interval = c(a, b), tol = 1e-5)
lmin <- opt_result$minimum
# Actualizar X
X =  rbind(X,X[k, ] - lmin * gradiente)
k <- k + 1
# Calcular las normas de X y el uevo X
normaX = norma(X[k,]-X[k-1,])/norma(X[k-1,])
tc = c(tc,normaX)
}
# Añadir al final la columna de resultados
X = cbind.data.frame(1:k,X,apply(X, 1, fx),tc)
# Ponerlo bonito para los resultados:
resu = as.data.frame(X)
names(resu) = c("Iter","X1","X2","Y","Tol")
resu = resu |> round(digits = 4)
# Devolver los resultados bonitos
return(resu)
}
rm(list=ls())
#### Paso 1 Definir los parametros iniciales ####
library(flextable)
fx = function(X){((X[1]^2+X[2]-11)^2 + (X[1] + X[2]^2-7)^2) |> as.numeric()}
x = c(0,0) # Punto inicial
tol1 = 0.001
tol2 = 0.001
# Paramertros para la derivada y el método de busqueda
a = 0
b = 1
# Reportar los resultados
resu = cauchy(fx,x,tol1,0,1)
rm(list=ls())
#### Paso 1 Definir los parametros iniciales ####
library(flextable)
fx = function(X){((X[1]^2+X[2]-11)^2 + (X[1] + X[2]^2-7)^2) |> as.numeric()}
x = c(0,0) # Punto inicial
tol1 = 0.001
tol2 = 0.001
# Paramertros para la derivada y el método de busqueda
a = 0
b = 1
# Reportar los resultados
resu = cauchy(fx,x,tol1,0,1)
rm(list=ls())
# Cargar la función y dar los parametros iniciales
source("Tarea 12. Busqueda Cauchy MAIN.R")
library(flextable)
fx = function(X){((X[1]^2+X[2]-11)^2 + (X[1] + X[2]^2-7)^2) |> as.numeric()}
x = c(0,0) # Punto inicial
tol1 = 0.001
tol2 = 0.001
# Paramertros para la derivada y el método de busqueda
a = 0
b = 1
# Reportar los resultados
resu = cauchy(fx,x,tol1,0,1)
autofit(theme_box(flextable(resu)))
resu
rm(list=ls())
knitr::opts_chunk$set(echo = F,
eval = T,
message = F,
warning = F)
# Cargar la función y dar los parametros iniciales
source("Tarea 12. Busqueda Cauchy MAIN.R")
library(flextable)
fx = function(X){((X[1]^2+X[2]-11)^2 + (X[1] + X[2]^2-7)^2) |> as.numeric()}
x = c(0,0) # Punto inicial
tol1 = 0.001
tol2 = 0.001
# Paramertros para la derivada y el método de busqueda
a = 0
b = 1
# Reportar los resultados
resu = cauchy(fx,x,tol1,0,1)
autofit(theme_box(flextable(resu)))
rm(list=ls())
fx = function(X){((X[1]^2+X[2]-11)^2 + (X[1] + X[2]^2-7)^2) |> as.numeric()}
labda = 100
x0 = c(0,0)
tol1 = tol2 = 0
tol1
tol2
tol1 = tol2 = 0.001
k = 0
### Funciones necesarias ###
#Función para calcular el gradiente
gradienten <- function(fx, X, h) {
D <- length(X)  # Dimensiones de la entrada
resu <- numeric(D)
f0 <- fx(X)     # Valor de la función en X actual
for (i in 1:D) {
perturbado <- X
perturbado[i] <- perturbado[i] + h
resu[i] <- (fx(perturbado) - f0) / h
}
return(resu)
}
matrix(c(1,0,0,1),nrow = 2)
###
H = matrix(c(-42.114,0,0,25.940),nrow = 2)
H
I = matrix(0,nrow = 2)
I
I = matrix(0,nrow = 2,ncol = 2)
I
diag(I) = 1
I
tol1 = tol2 = 0.001
labda = 100
x0 = c(0,0)
k = 0
###
H = matrix(c(-42.114,0,0,25.940),nrow = 2)
I = matrix(0,nrow = 2,ncol = 2)
diag(I) = 1
###
H + lambda
lambda = 100
x0 = c(0,0)
k = 0
###
H = matrix(c(-42.114,0,0,25.940),nrow = 2)
I = matrix(0,nrow = 2,ncol = 2)
diag(I) = 1
###
H + lambda
###
H = matrix(c(-42.114,0,0,25.940),nrow = 2)
I = matrix(0,nrow = 2,ncol = 2)
diag(I) = 1
H
lambda*I
###
H + lambda*I
S0 =solve(H + lambda*I)
S0
S0
xk
s0
###
S0 =solve(H + lambda*I)
S0
x0
S0
H + lambda*I
###
H = matrix(c(-42.114,0,0,25.940),nrow = 2)
I = matrix(0,nrow = 2,ncol = 2)
diag(I) = 1
H + lambda*I
###
H = matrix(c(-42.114,0,0,-25.940),nrow = 2)
I = matrix(0,nrow = 2,ncol = 2)
diag(I) = 1
###
S0 =solve(H + lambda*I)
S0
H + lambda*I
solve(H + lambda*I)%*%c(-14,22)
- solve(H + lambda*I)%*%c(-14,22)
###
S0 =- solve(H + lambda*I)%*%c(-14,22)
S0
###
S0 =- solve(H + lambda*I)%*%c(-14,-22)
S
S0
x0
###
S0 =- solve(H + lambda*I)%*%c(-14,-22)
x0 + S0
x0
c(1+1) + S0
S0
x0
xk = x0 + S0
xk
f(xk)
fx(xk)
fx(xk)-fx(x0)
xk = x0 + S0
xk
fx(xk)<fx(x0)
fx(xk)<fx(x0) # Se cumple, haz el paso 6
xk = x0 + S0
xk
fx(xk)
lambda = lambda/2
lambda
k+1
k = k+1
k
###
grad = c(-14,-22)
S0 =- solve(H + lambda*I)%*% grad
fx(c(2.980,2.046))
fx(xk)
fx(c(2.980,2.046))
