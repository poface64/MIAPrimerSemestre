# fx = función multivariable
# X = punto inicial
# tol = tolerancia
# a = Limite inferior de busqueda
# b = Limite superior de busqueda
# tol = Tolerancia permitida
# Parametros de inicio
# Función objetivo
fx = function(X){(X[1]^2+X[2]-11)^2 + (X[1] + X[2]^2-7)^2}
# Parametros de la función
X0 = c(0,0)
h = 0.001
a = 0.001
b = 1
tol = 0.001
# Resultado de la corrida de clase forzandolo un poco
# Resultado de la corrida de clase forzandolo un poco
res1 = conjugadas(fx,X0,tol,a,b)
# Reporta bonito los resultados
autofit(theme_box(flextable(res1)))
#### Evaluación con cambio de limites ####
# Parametros de la función
X0 = c(0,0)
a = 0.001
b = 1
tol = 0.001
# Resultado de la corrida de clase forzandolo un poco
# Resultado de la corrida de clase forzandolo un poco
res2 = conjugadas(fx,X0,tol,a,b)
# Reporta bonito los resultados
autofit(theme_box(flextable(res2)))
# Busqueda de direcciones conjugadas de Powell
# Librería para hacer las tablas bonitas
library(flextable)
# Llamo el código
source("Tarea 13. Conjugadas  MAIN.R")
# Declaro la función que se desea minimizar
#### Evaluación para el ejercicio de clase ####
# fx = función multivariable
# X = punto inicial
# tol = tolerancia
# a = Limite inferior de busqueda
# b = Limite superior de busqueda
# tol = Tolerancia permitida
# Parametros de inicio
# Función objetivo
fx = function(X){(X[1]^2+X[2]-11)^2 + (X[1] + X[2]^2-7)^2}
# Parametros de la función
X0 = c(0,0)
h = 0.001
a = 0.001
b = 1
tol = 0.001
# Resultado de la corrida de clase forzandolo un poco
# Resultado de la corrida de clase forzandolo un poco
res1 = conjugadas(fx,X0,tol,a,b)
# Reporta bonito los resultados
autofit(theme_box(flextable(res1)))
#### Evaluación con cambio de limites ####
# Parametros de la función
X0 = c(0,0)
h = 0.001
a = -10
b = 10
tol = 0.001
# Resultado de la corrida de clase forzandolo un poco
# Resultado de la corrida de clase forzandolo un poco
res2 = conjugadas(fx,X0,tol,a,b)
# Reporta bonito los resultados
autofit(theme_box(flextable(res2)))
#### Evaluación con cambio de limites ####
# Parametros de la función
X0 = c(0,0)
h = 0.001
a = -10
b = 10
tol = 0.001
# Resultado de la corrida de clase forzandolo un poco
# Resultado de la corrida de clase forzandolo un poco
res2 = conjugadas(fx,X0,tol,a,b)
# Reporta bonito los resultados
autofit(theme_box(flextable(res2)))
#### Evaluación con cambio de limites ####
# Parametros de la función
X0 = c(0,0)
h = 0.001
a = -10
b = 10
tol = 0.001
# Resultado de la corrida de clase forzandolo un poco
# Resultado de la corrida de clase forzandolo un poco
res2 = conjugadas(fx,X0,tol,a,b)
# Reporta bonito los resultados
autofit(theme_box(flextable(res2)))
rm(list=ls())
# Parametros de inicio
# Función objetivo
fx = function(X){(X[1]^2+X[2]-11)^2 + (X[1] + X[2]^2-7)^2}
# Parametros de inicio
# Función objetivo
fx = function(X){(X[1]^2+X[2]-11)^2 + (X[1] + X[2]^2-7)^2}
# Parametros de la función
X0 = c(0,0)
a = 0.001
b = 1
tol = 0.001
#### Paso 1 ####
# Dfine un punto inicial y dos parametros de terminación
x = X0
tol1 = tol2 = tol
gradienten <- function(fx, X, h) {
# Parametros de dimensionalidad
D <- length(X)  # Dimensiones de la entrada
resu <- numeric(D)  # Inicializamos el vector del gradiente
for (i in 1:D) {
# Crear copias de X para aplicar las perturbaciones
Xpos <- X
Xneg <- X
# Aplicar la perturbación en la dimensión i
Xpos[i] <- X[i] + h
Xneg[i] <- X[i] - h
# Calcular la diferencia de las evaluaciones
resu[i] <- (fx(Xpos) - fx(Xneg)) / (2 * h)
}
return(resu)
}
grad1 = gradienten(fx,x,tol1)
grad1
# Hacer k = 0
# Función que calcula la norma
norma <- function(VEC){sqrt(sum(VEC^2))}
norma(grad1)
#### Paso 3 ####
# Revisa si la norma del gradiente es menor a tol1
norma(grad1)
#### Paso 3 ####
# Revisa si la norma del gradiente es menor a tol1
norma(grad1)<=tol1
X0 = c(0,0,0)
fx = function(X){(X[1]^2 + X[2]^2 + X[3]^2 +
2*X[1]*X[2] + 3*X[1]*X[3]+ 4*X[2]*X[3])}
fx(x0)
X0 = c(0,0,0)
fx(X0)
X0 = c(0,0,0)+1
fx(X0)
fx(X0+2)
#### Paso 2 ####
# Calcular el gradiente
gradienten <- function(fx, X, h) {
# Parametros de dimensionalidad
D <- length(X)  # Dimensiones de la entrada
resu <- numeric(D)  # Inicializamos el vector del gradiente
for (i in 1:D) {
# Crear copias de X para aplicar las perturbaciones
Xpos <- X
Xneg <- X
# Aplicar la perturbación en la dimensión i
Xpos[i] <- X[i] + h
Xneg[i] <- X[i] - h
# Calcular la diferencia de las evaluaciones
resu[i] <- (fx(Xpos) - fx(Xneg)) / (2 * h)
}
return(resu)
}
tol1
gradienten(fx,x,tol1)
fx = function(X){(X[1]^2 + X[2]^2 + X[3]^2 +
2*X[1]*X[2] + 3*X[1]*X[3]+ 4*X[2]*X[3])}
fx
gradienten(fx,X0,tol1)
# Identificar laas dimenciones de la entrada
P = length(X0)
P = length(X0)
P
# Genero una matriz de PxP llena de 0
H = matrix(0,ncol =P,nrow = P)
H
# Genero una matriz de PxP llena de 0
H = matrix(0,ncol =P,nrow = P)
# Recorrer las filas y columnas
for (i in 1:3) {
for (j in 1:3) {
if (i == j) {
# Asignar 1 a la diagonal principal
H[i, j] <- 1
} else if (i > j) {
# Sumar posición fila y columna para la triangular inferior
H[i, j] <- i + j
} else if (i < j) {
# Proyectar el valor de la triangular inferior a la triangular superior
H[i, j] <- H[j, i]
}
}
}
H
i > j
# Genero una matriz de PxP llena de 0
H = matrix(0,ncol =P,nrow = P)
# Recorrer las filas y columnas
for (i in 1:3) {
for (j in 1:3) {
if (i == j) {
# Asignar 1 a la diagonal principal
H[i, j] <- 1
}else if (i > j) {
# Sumar posición fila y columna para la triangular inferior
H[i, j] <- i + j
# Proyectar el valor de la triangular inferior a la triangular superior
H[j, i] <- H[i, j]
}
}
}
H
# Genero una matriz de PxP llena de 0
H = matrix(0,ncol =P,nrow = P)
H
# Recorrer las filas y columnas
for (i in 1:P) {
for (j in 1:P) {
# Condición para la diagonal
if (i == j) {
# Asignar 1 a la diagonal principal
H[i, j] <- 1
# Condición para calcular los valores de la diagonal inferior
}else if (i > j) {
# Sumar posición fila y columna para la triangular inferior
H[i, j] <- i + j
# Proyectar el valor de la triangular inferior a la triangular superior
H[j, i] <- H[i, j]
}
}
}
H
# Parametros de inicio
# Función objetivo
fx = function(X){(X[1]^2+X[2]-11)^2 + (X[1] + X[2]^2-7)^2}
# Parametros de la función
X0 = c(0,0)
# Genero una matriz de PxP llena de 0
H = matrix(0,ncol =P,nrow = P)
# Recorrer las filas y columnas
for (i in 1:P) {
for (j in 1:P) {
# Condición para la diagonal
if (i == j) {
# Hacerme bola con los calculos numericos
# Asignar 1 a la diagonal principal
H[i, j] <- 1
# Condición para calcular los valores de la diagonal inferior
}else if (i > j) {
# Sumar posición fila y columna para la triangular inferior
H[i, j] <- i + j
# Proyectar el valor de la triangular inferior a la triangular superior
H[j, i] <- H[i, j]
}
}
}
H
X0
# Identificar laas dimenciones de la entrada
P = length(X0)
# Genero una matriz de PxP llena de 0
H = matrix(0,ncol =P,nrow = P)
H
# Recorrer las filas y columnas
for (i in 1:P) {
for (j in 1:P) {
# Condición para la diagonal
if (i == j) {
# Hacerme bola con los calculos numericos
# Asignar 1 a la diagonal principal
H[i, j] <- 1
# Condición para calcular los valores de la diagonal inferior
}else if (i > j) {
# Sumar posición fila y columna para la triangular inferior
H[i, j] <- i + j
# Proyectar el valor de la triangular inferior a la triangular superior
H[j, i] <- H[i, j]
}
}
}
H
X0
X0+0.001
fx(c(X0[1]+0.001,X0[2]-0.001))
fx(X0+0.001)
fx(X0+0.001)-fx(c(X0[1]+0.001,X0[2]-0.001))
fx(c(X0[1]-0.001,X0[2]+0.001))
fx(X0+0.001)-fx(c(X0[1]+0.001,X0[2]-0.001))-fx(c(X0[1]-0.001,X0[2]+0.001))
-fx(c(X0[1]-0.001,X0[2]+0.001))
fx(X0-0.001)
fx(X0+0.001) - fx(c(X0[1]+0.001,X0[2]-0.001)) -
fx(c(X0[1]-0.001,X0[2]+0.001))+fx(X0-0.001)
(4*tol*tol)
(fx(X0+0.001) - fx(c(X0[1]+0.001,X0[2]-0.001)) -
fx(c(X0[1]-0.001,X0[2]+0.001))+fx(X0-0.001))/(4*tol*tol)
c(X0[1]+tol)
fx(c(X0[1]+tol),X0[2])
X0[2]
fx(c(X0[1]+tol,X0[2]))
fx(X0)
2*fx(X0)
fx(c(X0[1]+tol,X0[2])) - 2*fx(X0) + fx(c(X0[1]-tol,X0[2]))
tol^2
d1 = fx(c(X0[1]+tol,X0[2])) - 2*fx(X0) + fx(c(X0[1]-tol,X0[2]))/(tol^2)
d1
4*(-11) + 2
# Hacerme bola con los calculos numericos
d1 = fx(c(X0[1]+tol,X0[2])) - 2*fx(X0) + fx(c(X0[1]-tol,X0[2]))/(tol^2)
d1
# Hacerme bola con los calculos numericos
d1 = (fx(c(X0[1]+tol,X0[2])) - 2*fx(X0) + fx(c(X0[1]-tol,X0[2])))/(tol^2)
d1
# Genero una matriz de PxP llena de 0
H = matrix(0,ncol =P,nrow = P)
# Recorrer las filas y columnas
for (i in 1:P) {
for (j in 1:P) {
# Condición para la diagonal
if (i == j) {
# Hacerme bola con los calculos numericos
d1 = (fx(c(X0[1]+tol,X0[2])) - 2*fx(X0) + fx(c(X0[1]-tol,X0[2])))/(tol^2)
# Asignar 1 a la diagonal principal
H[i, j] <- 1
# Condición para calcular los valores de la diagonal inferior
}else if (i > j) {
# Sumar posición fila y columna para la triangular inferior
H[i, j] <- (fx(X0+0.001) - fx(c(X0[1]+0.001,X0[2]-0.001)) -
fx(c(X0[1]-0.001,X0[2]+0.001))+fx(X0-0.001))/(4*tol*tol)
# Proyectar el valor de la triangular inferior a la triangular superior
H[j, i] <- H[i, j]
}
}
}
H
# Genero una matriz de PxP llena de 0
H = matrix(0,ncol =P,nrow = P)
# Recorrer las filas y columnas
for (i in 1:P) {
for (j in 1:P) {
# Condición para la diagonal
if (i == j) {
# Hacerme bola con los calculos numericos
d1 = (fx(c(X0[1]+tol,X0[2])) - 2*fx(X0) + fx(c(X0[1]-tol,X0[2])))/(tol^2)
# Asignar 1 a la diagonal principal
H[i, j] <- d1
# Condición para calcular los valores de la diagonal inferior
}else if (i > j) {
# Sumar posición fila y columna para la triangular inferior
H[i, j] <- (fx(X0+0.001) - fx(c(X0[1]+0.001,X0[2]-0.001)) -
fx(c(X0[1]-0.001,X0[2]+0.001))+fx(X0-0.001))/(4*tol*tol)
# Proyectar el valor de la triangular inferior a la triangular superior
H[j, i] <- H[i, j]
}
}
}
H
round(H,4)
rm(list=ls())
# Cargar la función principal
source("Tarea 14.1 Newthon puro MAIN.R")
#### Evaluación de clase ####
# Función objetivo
fx = function(X){(X[1]^2+X[2]-11)^2 + (X[1] + X[2]^2-7)^2}
# Parametros de la función
X0 = c(0,0)
a = 0
b = 5
tol = 0.001
NH(fx,X0,tol,a,b)
rm(list=ls())
# Parametros de inicio
# Función objetivo
fx = function(X){(X[1]^2+X[2]-11)^2 + (X[1] + X[2]^2-7)^2}
# Parametros de la función
X0 = c(0,0)
a = 0.001
b = 1
tol = 0.001
#### Paso 1, elegir un punto inicial
# Definir internamente las funciones que necesito
## Función que calcula la norma
norma <- function(VEC){sqrt(sum(VEC^2))}
## Función del gradiente
gradienten <- function(fx, X, h) {
# Parametros de dimensionalidad
D <- length(X)  # Dimensiones de la entrada
resu <- numeric(D)  # Inicializamos el vector del gradiente
for (i in 1:D) {
# Crear copias de X para aplicar las perturbaciones
Xpos <- X
Xneg <- X
# Aplicar la perturbación en la dimensión i
Xpos[i] <- X[i] + h
Xneg[i] <- X[i] - h
# Calcular la diferencia de las evaluaciones
resu[i] <- (fx(Xpos) - fx(Xneg)) / (2 * h)
}
return(resu)
}
## Función para calcular la Hessiana
hess =  function(fx,X0){
# Definir las dimensiones
P <- length(X0) # Dimensión
tol <- 0.001 # Perturbación numérica
# Inicializar la matriz Hessiana
H <- matrix(0, ncol = P, nrow = P)
# Calcular la Hessiana
for (i in 1:P) {
for (j in 1:P) {
if (i == j) {
# Diagonal principal: segunda derivada respecto a la misma variable
# Generar el vector de perturbaciones
vec_perturb <- numeric(P)
# Dar el valor del error de pertubación en la variable i-esima
vec_perturb[i] <- tol
H[i, j] <- (fx(X0 + vec_perturb) - 2 * fx(X0) + fx(X0 - vec_perturb)) / (tol^2)
} else if (i > j) {
# Derivadas cruzadas (fuera de la diagonal)
vec_perturb_i <- numeric(P) # Un vector para perturbar la variable i
vec_perturb_j <- numeric(P) # Un vector para perturbar la variable j
vec_perturb_i[i] <- tol #Dar el valor de la pertubación para i
vec_perturb_j[j] <- tol #Dar el valor de la pertubación para j
# Fórmula para derivadas cruzadas
H[i, j] <- (fx(X0 + vec_perturb_i + vec_perturb_j) -
fx(X0 + vec_perturb_i - vec_perturb_j) -
fx(X0 - vec_perturb_i + vec_perturb_j) +
fx(X0 - vec_perturb_i - vec_perturb_j)) / (4 * tol^2)
# Simetría: H[j, i] = H[i, j]
H[j, i] <- H[i, j]
}
}
}
# Devolver la matriz Hessiana como salida
return(H)
}
rm(list=ls())
# Parametros de inicio
# Función objetivo
fx = function(X){(X[1]^2+X[2]-11)^2 + (X[1] + X[2]^2-7)^2}
# Parametros de la función
X0 = c(0,0)
a = 0.001
b = 1
tol = 0.001
#### Paso 1, elegir un punto inicial
# Definir internamente las funciones que necesito
## Función que calcula la norma
norma <- function(VEC){sqrt(sum(VEC^2))}
## Función del gradiente
gradienten <- function(fx, X, h) {
# Parametros de dimensionalidad
D <- length(X)  # Dimensiones de la entrada
resu <- numeric(D)  # Inicializamos el vector del gradiente
for (i in 1:D) {
# Crear copias de X para aplicar las perturbaciones
Xpos <- X
Xneg <- X
# Aplicar la perturbación en la dimensión i
Xpos[i] <- X[i] + h
Xneg[i] <- X[i] - h
# Calcular la diferencia de las evaluaciones
resu[i] <- (fx(Xpos) - fx(Xneg)) / (2 * h)
}
return(resu)
}
# Definir el K inicial
k = 0
M = 100
M
# Calcular f(X) en el punto y guardarlo
FX = c(fx(X0))
FX
knitr::opts_chunk$set(echo = F,
eval = T,
message = F,
warning = F)
# Busqueda de direcciones conjugadas de Powell
# Librería para hacer las tablas bonitas
library(flextable)
knitr::opts_chunk$set(echo = F,
eval = T,
message = F,
warning = F)
# Llamo el código
source("Tarea 14 Marquart MAIN.R")
# Busqueda de direcciones conjugadas de Powell
# Librería para hacer las tablas bonitas
library(flextable)
# Llamo el código
source("Tarea 14 Marquart MAIN.R")
# Declaro la función que se desea minimizar
#### Evaluación para el ejercicio de clase ####
# fx = función multivariable
# X = punto inicial
# tol = tolerancia
# a = Limite inferior de busqueda
# b = Limite superior de busqueda
# tol = Tolerancia permitida
#### Evaluación de clase ####
# Función objetivo
fx = function(X){(X[1]^2+X[2]-11)^2 + (X[1] + X[2]^2-7)^2}
# Parametros de la función
X0 = c(0,0)
a = 0
b = 5
tol = 0.001
# Reporte
res1 = NH(fx,X0,tol,a,b)
# Reporta bonito los resultados
autofit(theme_box(flextable(res1)))
